{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70f127f9",
   "metadata": {},
   "source": [
    "# CSCE 580 — Quiz 2 (Fall 2025)\n",
    "**Date:** October 7, 2025  \n",
    "**Student:** David Dinh\n",
    "\n",
    "This notebook implements the **code** portions of Quiz 2 and prepares the expected folder structure and artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d80f8b50",
   "metadata": {},
   "source": [
    "## Q1 — Compare Energy Consumption (10 pts)\n",
    "\n",
    "Use the tool at: https://symbio6.nl/en/apps/ai-vs-simple-energy.html\n",
    "\n",
    "**Instructions:**\n",
    "1. Pick **three different settings** (e.g., translation, summarization, image captioning).\n",
    "2. Record AI (LLM) vs Classical energy usage.\n",
    "3. Compute the **difference** and **average difference**, and decide which approach is higher on average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7da454a",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#  Enter your measurements here (replace example numbers with real values from the website)\n",
    "import pandas as pd\n",
    "\n",
    "df_energy = pd.DataFrame({\n",
    "    \"Setting\": [\"Searching\", \"Math\", \"Image Captioning\"],  \n",
    "    \"AI_Energy_Wh\": [2.9, 1.7, 2.9],        \n",
    "    \"Classical_Energy_Wh\": [0.3, 0.01, 0.3], \n",
    "})\n",
    "df_energy[\"Difference_Wh\"] = df_energy[\"AI_Energy_Wh\"] - df_energy[\"Classical_Energy_Wh\"]\n",
    "display(df_energy)\n",
    "\n",
    "avg_diff = df_energy[\"Difference_Wh\"].mean()\n",
    "winner = \"AI (LLM)\" if avg_diff > 0 else \"Classical\"\n",
    "print(f\"Average difference across 3 settings: {avg_diff:.3f} Wh\")\n",
    "print(f\"On average, {winner} uses more energy.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5448367b",
   "metadata": {},
   "source": [
    "## Q2 — Convert Recipes to R3 JSON (90 pts)\n",
    "\n",
    "You must select **two recipes** (not the sample Egg Drop soup). Save their **cleaned** text as:\n",
    "\n",
    "- `data/original_recipe1.txt`\n",
    "- `data/original_recipe2.txt`\n",
    "\n",
    "Each cleaned file should include lines like:\n",
    "```\n",
    "Recipe Name: <Name>\n",
    "Source: <URL>\n",
    "\n",
    "Ingredients:\n",
    "- item 1\n",
    "- item 2\n",
    "\n",
    "Instructions:\n",
    "1. Step one...\n",
    "2. Step two...\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6771259a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Quick peek: show first few lines of the cleaned recipe files if they exist\n",
    "from pathlib import Path\n",
    "\n",
    "def head(path, n=20):\n",
    "    p = Path(path)\n",
    "    if not p.exists():\n",
    "        print(f\" {path} not found.\")\n",
    "        return\n",
    "    print(f\"--- {path} ---\")\n",
    "    with p.open(encoding=\"utf-8\") as f:\n",
    "        for i, line in enumerate(f):\n",
    "            if i >= n: break\n",
    "            print(line.rstrip())\n",
    "\n",
    "head(\"data/original_recipe1.txt\")\n",
    "print()\n",
    "head(\"data/original_recipe2.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b077fe",
   "metadata": {},
   "source": [
    "### Utilities — Parse cleaned text and build R3 JSON\n",
    "\n",
    "This section provides helper functions used to:\n",
    "- Parse the cleaned `.txt` files\n",
    "- Enforce **single-action** imperative instruction steps\n",
    "- Generate PF1/PF2/PF3 style JSON and PP (partial-stitched) JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db482d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers to parse and generate JSONs\n",
    "import json, re\n",
    "from pathlib import Path\n",
    "\n",
    "def parse_cleaned_txt(path: Path):\n",
    "    \"\"\"Parse a cleaned recipe .txt into a dict with name, provenance, ingredients, instructions.\"\"\"\n",
    "    text = Path(path).read_text(encoding=\"utf-8\")\n",
    "    text = text.replace(\"\\r\\n\", \"\\n\")\n",
    "    name_match = re.search(r\"Recipe Name:\\s*(.+)\", text, re.IGNORECASE)\n",
    "    src_match  = re.search(r\"Source:\\s*(.+)\", text, re.IGNORECASE)\n",
    "    recipe_name = name_match.group(1).strip() if name_match else \"\"\n",
    "    data_provenance = src_match.group(1).strip() if src_match else \"\"\n",
    "\n",
    "    ing_match = re.search(r\"Ingredients:\\s*(.*?)(?:\\n\\s*\\n|Instructions:)\", text, re.IGNORECASE | re.DOTALL)\n",
    "    ing_block = ing_match.group(1).strip() if ing_match else \"\"\n",
    "    instr_match = re.search(r\"Instructions:\\s*(.*)\", text, re.IGNORECASE | re.DOTALL)\n",
    "    instr_block = instr_match.group(1).strip() if instr_match else \"\"\n",
    "\n",
    "    ingredients = []\n",
    "    for line in ing_block.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        line = re.sub(r\"^[-•]\\s*\", \"\", line)  # remove leading bullet/dash\n",
    "        ingredients.append(line)\n",
    "\n",
    "    steps = []\n",
    "    for line in instr_block.splitlines():\n",
    "        line = line.strip()\n",
    "        if not line: continue\n",
    "        line = re.sub(r\"^(step\\d+|\\d+[\\.\\)])\\s*\", \"\", line, flags=re.IGNORECASE)\n",
    "        steps.append(line)\n",
    "\n",
    "    return {\n",
    "        \"recipe_name\": recipe_name,\n",
    "        \"data_provenance\": data_provenance,\n",
    "        \"ingredients\": ingredients,\n",
    "        \"instructions\": steps\n",
    "    }\n",
    "\n",
    "def to_imperative_atomic(steps):\n",
    "    \"\"\"Enforce single-action, imperative, short sentences. Heuristic-only.\"\"\"\n",
    "    out = []\n",
    "    for s in steps:\n",
    "        s = s.strip()\n",
    "        parts = re.split(r\"\\s+and\\s+\", s)\n",
    "        for p in parts:\n",
    "            p = p.strip()\n",
    "            if not p: continue\n",
    "            p = p.rstrip(\". \").strip()\n",
    "            p = p[:1].upper() + p[1:]\n",
    "            if not p.endswith(\".\"):\n",
    "                p += \".\"\n",
    "            out.append(p)\n",
    "    return out\n",
    "\n",
    "def make_pf1_json(recipe):\n",
    "    return {\n",
    "        \"recipe_name\": recipe[\"recipe_name\"],\n",
    "        \"data_provenance\": recipe[\"data_provenance\"],\n",
    "        \"macronutrients\": {},\n",
    "        \"ingredients\": recipe[\"ingredients\"],\n",
    "        \"instructions\": to_imperative_atomic(recipe[\"instructions\"]),\n",
    "    }\n",
    "\n",
    "def make_pf2_json(recipe):\n",
    "    return {\n",
    "        \"recipe_name\": recipe[\"recipe_name\"],\n",
    "        \"data_provenance\": recipe[\"data_provenance\"],\n",
    "        \"macronutrients\": {},\n",
    "        \"ingredients\": recipe[\"ingredients\"],\n",
    "        \"instructions\": to_imperative_atomic(recipe[\"instructions\"]),\n",
    "    }\n",
    "\n",
    "def make_pf3_json(recipe):\n",
    "    atomic = to_imperative_atomic(recipe[\"instructions\"])\n",
    "    cleaned = []\n",
    "    for s in atomic:\n",
    "        s2 = re.sub(r\"\\s*\\([^)]*\\)\", \"\", s).strip()\n",
    "        s2 = re.sub(r\"\\s*;\\s*.*$\", \".\", s2)\n",
    "        if not s2.endswith(\".\"):\n",
    "            s2 += \".\"\n",
    "        cleaned.append(s2)\n",
    "    return {\n",
    "        \"recipe_name\": recipe[\"recipe_name\"],\n",
    "        \"data_provenance\": recipe[\"data_provenance\"],\n",
    "        \"macronutrients\": {},\n",
    "        \"ingredients\": recipe[\"ingredients\"],\n",
    "        \"instructions\": cleaned,\n",
    "    }\n",
    "\n",
    "def write_json(obj, path):\n",
    "    Path(path).write_text(json.dumps(obj, indent=2), encoding=\"utf-8\")\n",
    "    return path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888bc6fc",
   "metadata": {},
   "source": [
    "### Generate PF1 / PF2 / PF3 and PP JSONs\n",
    "\n",
    "This cell reads the two cleaned recipe files and writes **8 JSON files**:\n",
    "\n",
    "- `recipe1_pf1.json`, `recipe1_pf2.json`, `recipe1_pf3.json`, `recipe1_pp.json`\n",
    "- `recipe2_pf1.json`, `recipe2_pf2.json`, `recipe2_pf3.json`, `recipe2_pp.json`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5a4b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to generate all JSONs (edit input paths if needed)\n",
    "r1 = parse_cleaned_txt(\"data/original_recipe1.txt\")\n",
    "r2 = parse_cleaned_txt(\"data/original_recipe2.txt\")\n",
    "\n",
    "# PF1/PF2/PF3\n",
    "write_json(make_pf1_json(r1), \"data/recipe1_pf1.json\")\n",
    "write_json(make_pf2_json(r1), \"data/recipe1_pf2.json\")\n",
    "write_json(make_pf3_json(r1), \"data/recipe1_pf3.json\")\n",
    "\n",
    "write_json(make_pf1_json(r2), \"data/recipe2_pf1.json\")\n",
    "write_json(make_pf2_json(r2), \"data/recipe2_pf2.json\")\n",
    "write_json(make_pf3_json(r2), \"data/recipe2_pf3.json\")\n",
    "\n",
    "# PP (partial stitch): reuse parsed ingredients/instructions (as if extracted separately)\n",
    "pp1 = {\n",
    "    \"recipe_name\": r1[\"recipe_name\"] or \"Recipe 1\",\n",
    "    \"data_provenance\": r1[\"data_provenance\"],\n",
    "    \"macronutrients\": {},\n",
    "    \"ingredients\": r1[\"ingredients\"],\n",
    "    \"instructions\": to_imperative_atomic(r1[\"instructions\"]),\n",
    "}\n",
    "pp2 = {\n",
    "    \"recipe_name\": r2[\"recipe_name\"] or \"Recipe 2\",\n",
    "    \"data_provenance\": r2[\"data_provenance\"],\n",
    "    \"macronutrients\": {},\n",
    "    \"ingredients\": r2[\"ingredients\"],\n",
    "    \"instructions\": to_imperative_atomic(r2[\"instructions\"]),\n",
    "}\n",
    "write_json(pp1, \"data/recipe1_pp.json\")\n",
    "write_json(pp2, \"data/recipe2_pp.json\")\n",
    "\n",
    "from pathlib import Path\n",
    "for f in [\n",
    "    \"data/recipe1_pf1.json\", \"data/recipe1_pf2.json\", \"data/recipe1_pf3.json\", \"data/recipe1_pp.json\",\n",
    "    \"data/recipe2_pf1.json\", \"data/recipe2_pf2.json\", \"data/recipe2_pf3.json\", \"data/recipe2_pp.json\",\n",
    "]:\n",
    "    print(\" created:\", Path(f).resolve())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328abd37",
   "metadata": {},
   "source": [
    "### Evaluate Goodness Scores (Q2c)\n",
    "\n",
    "Rubric:\n",
    "- **50** points for valid JSON\n",
    "- **+10** each if the JSON contains: `recipe_name`, `data_provenance`, `macronutrients`, `ingredients`, `instructions`  \n",
    "Max **100**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa378b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluator\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "fields = ['recipe_name', 'data_provenance', 'macronutrients', 'ingredients', 'instructions']\n",
    "\n",
    "def evaluate_goodness(json_path: Path) -> int:\n",
    "    try:\n",
    "        data = json.loads(Path(json_path).read_text(encoding=\"utf-8\"))\n",
    "    except Exception:\n",
    "        return 0  # invalid JSON file\n",
    "    score = 50\n",
    "    for k in fields:\n",
    "        if k in data:\n",
    "            score += 10\n",
    "    return min(score, 100)\n",
    "\n",
    "files = [\n",
    "    \"data/recipe1_pf1.json\",\"data/recipe1_pf2.json\",\"data/recipe1_pf3.json\",\"data/recipe1_pp.json\",\n",
    "    \"data/recipe2_pf1.json\",\"data/recipe2_pf2.json\",\"data/recipe2_pf3.json\",\"data/recipe2_pp.json\",\n",
    "]\n",
    "\n",
    "rows = []\n",
    "for f in files:\n",
    "    p = Path(f)\n",
    "    if p.exists():\n",
    "        rows.append({\"file\": f, \"score\": evaluate_goodness(p)})\n",
    "    else:\n",
    "        rows.append({\"file\": f, \"score\": None})\n",
    "\n",
    "df_scores = pd.DataFrame(rows).sort_values(by=[\"file\"])\n",
    "display(df_scores)\n",
    "\n",
    "# Highest per recipe\n",
    "best_r1 = df_scores[df_scores[\"file\"].str.contains(\"recipe1\")][\"score\"].max()\n",
    "best_r2 = df_scores[df_scores[\"file\"].str.contains(\"recipe2\")][\"score\"].max()\n",
    "print(f\"Best Recipe 1 score: {best_r1}\")\n",
    "print(f\"Best Recipe 2 score: {best_r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcc6cdc",
   "metadata": {},
   "source": [
    "### Create AI Test Case Doc (Q2d)\n",
    "\n",
    "This creates a starter **`docs/recipe-testcase.md`** following the provided template structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd49f8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "testcase = r\"\"\"# AI Test Case — Recipe to R3 JSON\n",
    "\n",
    "## 1. Objective\n",
    "Convert cleaned recipe text into structured R3 JSON for use by a robotic chef.\n",
    "\n",
    "## 2. Inputs\n",
    "- Two cleaned recipes in `data/original_recipe1.txt` and `data/original_recipe2.txt`.\n",
    "- Prompt-Full strategies: PF1, PF2, PF3\n",
    "- Prompt-Partial strategies: PP-1 (ingredients), PP-2 (instructions)\n",
    "\n",
    "## 3. Expected Behavior\n",
    "- Valid JSON object with keys: `recipe_name`, `data_provenance`, `macronutrients`, `ingredients`, `instructions`.\n",
    "- Each instruction is a single, imperative action.\n",
    "\n",
    "## 4. Procedure\n",
    "1. Use PF1, PF2, PF3 prompts separately for each recipe → save JSONs in `data/`.\n",
    "2. Use PP-1 and PP-2 to extract ingredients and instructions, then stitch into full JSON in this notebook.\n",
    "3. Run the goodness evaluator on all 8 JSON files.\n",
    "\n",
    "## 5. Evaluation Criteria (Rubric)\n",
    "- 50 points for valid JSON.\n",
    "- +10 points each for the presence of the five required fields (max 100).\n",
    "\n",
    "## 6. Results\n",
    "- Recipe 1: list PF1/PF2/PF3/PP scores.\n",
    "- Recipe 2: list PF1/PF2/PF3/PP scores.\n",
    "\n",
    "## 7. Observations\n",
    "- Which approach (full vs partial) performed better and why?\n",
    "- Any common formatting errors?\n",
    "\n",
    "\"\"\"\n",
    "Path(\"docs/recipe-testcase.md\").write_text(testcase, encoding=\"utf-8\")\n",
    "print(\" Wrote docs/recipe-testcase.md\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (.venv-adl)",
   "language": "python",
   "name": "py312-adl"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
